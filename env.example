# AI Provider Configuration
# Set this to 'openai', 'ollama', or 'anthropic' to switch between providers
AI_PROVIDER=openai

# OpenAI Configuration (used when AI_PROVIDER=openai)
OPENAI_API_KEY=your-openai-api-key-here
OPENAI_MODEL_NAME=gpt-4-turbo-preview

# Anthropic Configuration (used when AI_PROVIDER=anthropic)
ANTHROPIC_API_KEY=your-anthropic-api-key-here
ANTHROPIC_MODEL_NAME=claude-3-5-sonnet-20241022

# Ollama Configuration (used when AI_PROVIDER=ollama)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL_NAME=deepseek-r1:32b
# Timeout in seconds for Ollama requests (overrides config file settings)
# Recommended: 180-300 for large models like deepseek-r1:70b, 120-180 for smaller models
OLLAMA_TIMEOUT=240

# Rate Limiting Environment
# Options: production, test, development, emergency
RATE_LIMIT_ENV=production

# Debug Configuration
# Set to full path of file containing list of files to process in debug mode
# One file path per line, empty or commented out to disable debug mode
# DEBUGFILE=/path/to/debug_files.txt

# Output Configuration
OUTPUT_DIR=./output

# Logging Configuration
LOG_LEVEL=INFO
LOG_FILE=logs/java_analysis.log

# Weaviate Configuration
WEAVIATE_URL=http://localhost:8080
WEAVIATE_COLLECTION_PREFIX=java_codebase

# Java Source Directory Configuration
# This is the path to your Java/JSP source code to analyze
JAVA_SOURCE_DIR=/path/to/your/java/source
