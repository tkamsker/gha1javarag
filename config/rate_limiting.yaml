# Rate Limiting Configuration
# Adjust these settings based on your OpenAI API plan and requirements

# Production settings (conservative)
production:
  requests_per_minute: 15
  requests_per_hour: 800
  delay_between_requests: 4.0
  exponential_backoff_base: 2.0
  max_retries: 5
  quota_exceeded_wait_time: 3600  # 1 hour wait when quota exceeded
  ollama_timeout: 120  # 2 minutes for Ollama requests

# Test settings (very conservative)
test:
  requests_per_minute: 10
  requests_per_hour: 500
  delay_between_requests: 8.0
  exponential_backoff_base: 2.0
  max_retries: 5
  quota_exceeded_wait_time: 3600  # 1 hour wait when quota exceeded
  ollama_timeout: 60  # 1 minute for Ollama requests (faster debugging)

# Development settings (more aggressive)
development:
  requests_per_minute: 20
  requests_per_hour: 1000
  delay_between_requests: 2.0
  exponential_backoff_base: 2.0
  max_retries: 3
  quota_exceeded_wait_time: 3600  # 1 hour wait when quota exceeded
  ollama_timeout: 90  # 1.5 minutes for Ollama requests

# Emergency settings (very restrictive)
emergency:
  requests_per_minute: 5
  requests_per_hour: 200
  delay_between_requests: 10.0
  exponential_backoff_base: 2.0
  max_retries: 5
  quota_exceeded_wait_time: 7200  # 2 hours wait when quota exceeded (more conservative)
  ollama_timeout: 30  # 30 seconds for Ollama requests (very fast debugging) 

# Hardcore 
# Development settings (more aggressive)
hardcore:
  requests_per_minute: 20
  requests_per_hour: 1000
  delay_between_requests: 2.0
  exponential_backoff_base: 2.0
  max_retries: 3
  quota_exceeded_wait_time: 3600  # 1 hour wait when quota exceeded
  ollama_timeout: 90  # 1.5 minutes for Ollama requests