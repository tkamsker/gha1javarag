# =============================
# Java Codebase Analysis Tool - Environment Configuration
# =============================
# Copy this file to .env and configure your specific values
# DO NOT commit .env to version control - it may contain sensitive information

# =============================
# Core Paths
# =============================
# Mandatory: root directory containing first-level project folders
# Each first-level subdirectory will be treated as a separate project
JAVA_SOURCE_DIR=/absolute/or/relative/path/to/source-root
# JAVA_SOURCE_DIR=/Users/thomaskamsker/Documents/Atom/vron.one/playground/java


# Where JSON catalogs, logs, and generated requirements are written
OUTPUT_DIR=./output

# =============================
# Weaviate (Vector Database)
# =============================
# Weaviate instance URL - local development default
WEAVIATE_URL=http://localhost:8080

# API key for Weaviate (leave empty if anonymous access is enabled)
# For local development, you can often leave this empty
WEAVIATE_API_KEY=

# Connection timeout in seconds
WEAVIATE_TIMEOUT=60

# Batch size for upserting data to Weaviate (tune for performance)
WEAVIATE_BATCH_SIZE=256

# =============================
# Embedding Configuration
# =============================
# Choose embedding pipeline:
# - weaviate_ollama: Use Weaviate's text2vec-ollama module (recommended)
# - client: Generate embeddings client-side using external API
EMBEDDING_PROVIDER=weaviate_ollama

# Model for text2vec-ollama (adjust to your local Ollama model)
EMBEDDING_MODEL=nomic-embed-text

# =============================
# AI Provider Configuration
# =============================
# Switch between 'openai', 'ollama', or 'anthropic' for generation/summarization
# This affects summaries, requirements generation, and LLM-assisted parsing
AI_PROVIDER=ollama

# =============================
# OpenAI Configuration
# =============================
# Only used when AI_PROVIDER=openai
OPENAI_API_KEY=sk-your-openai-api-key-here
OPENAI_API_BASE=https://api.openai.com/v1
OPENAI_API_TYPE=openai
OPENAI_API_VERSION=2024-02-15-preview
OPENAI_MODEL_NAME=gpt-4o
OPENAI_EMBED_MODEL=text-embedding-3-large

# =============================
# Ollama Configuration (Local)
# =============================
# Only used when AI_PROVIDER=ollama
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL_NAME=danielsheep/Qwen3-Coder-30B-A3B-Instruct-1M-Unsloth
OLLAMA_TIMEOUT=240

# For client-side embeddings with Ollama (when EMBEDDING_PROVIDER=client)
LOCAL_EMBED_URL=http://localhost:11435/embed
LOCAL_EMBED_MODEL=nomic-embed-text

# =============================
# Anthropic Configuration
# =============================
# Only used when AI_PROVIDER=anthropic
ANTHROPIC_API_KEY=sk-ant-your-anthropic-api-key-here
ANTHROPIC_API_BASE=https://api.anthropic.com
ANTHROPIC_MODEL_NAME=claude-3-5-sonnet-20240620

# =============================
# Processing Controls
# =============================
# Maximum file size in bytes (2MB default)
MAX_FILE_BYTES=2000000

# File types to include in processing (comma-separated)
INCLUDE_FILE_TYPES=.java,.jsp,.tsp,.xml,.html,.js,.sql,.properties,.json,.md,.css,.ui.xml,.gwt.xml

# Directories to exclude from processing (comma-separated)
EXCLUDE_DIRS=.git,node_modules,build,out,target,dist,.idea,.vscode,.gradle

# =============================
# Rate Limiting / Runtime Mode
# =============================
# Options: production | development | test | emergency
# Controls API rate limiting and processing behavior
RATE_LIMIT_ENV=development

# =============================
# Logging Configuration
# =============================
# Log level: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO

# Enable detailed processing logs
VERBOSE_LOGGING=false

# =============================
# Performance Tuning
# =============================
# Number of parallel workers for file processing
MAX_WORKERS=4

# Chunk overlap percentage (10-20% recommended)
CHUNK_OVERLAP_PERCENT=15

# Maximum retry attempts for failed operations
MAX_RETRIES=3

# =============================
# Development/Testing
# =============================
# Enable dry-run mode (process files but don't upsert to Weaviate)
DRY_RUN=false

# Skip Weaviate schema creation (assumes schemas already exist)
SKIP_SCHEMA_CREATION=false

# Generate sample data for testing
GENERATE_SAMPLE_DATA=false
